{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36df77a3-d5b2-4559-92ab-9a95179a2f3b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18187eb-f7b4-4991-88bd-4070c97ae6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu118\n"
     ]
    }
   ],
   "source": [
    "# Download dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0069be-0c5d-4a04-9133-4567b95e7cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a82731-0695-432f-92c9-69d8afff488e",
   "metadata": {},
   "source": [
    "# Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f0bd0f-caad-4860-9ae4-0eb1621e06a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../data/b200c-lego-classification-dataset')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set path to data\n",
    "data_path = Path(\"../data\")\n",
    "image_path = data_path / \"b200c-lego-classification-dataset\"\n",
    "\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e081ee-4cc2-4dcd-a2f4-8d62aa7ea51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67deec66-20fb-494a-86b6-ced773f44901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640000 \n",
      " 160000\n"
     ]
    }
   ],
   "source": [
    "# Make data folder into dataset\n",
    "full_dataset = datasets.ImageFolder(root=image_path,\n",
    "                                  transform=data_transform,\n",
    "                                  target_transform=None)\n",
    "\n",
    "# Split into training and testing data\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_data, test_data = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(train_data), \"\\n\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25357262-efcb-4816-beed-96c7c8c1c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Make dataset into dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba2591-ac1d-4636-b1f4-43d7897c6606",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f695ec28-04eb-4fe7-987a-dbf88fbe554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer a model (efficientnet_b0)\n",
    "# weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights\n",
    "# efficientnet_b0 = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93a23c92-6485-4f7b-b75d-efb4d4fab97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss, optimizer and accuracy function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb32d7d-b8e5-4157-9114-15a65582d34d",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb6192c-a742-464b-983b-59d4e9c96d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the trainingloop\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        efficientnet_b0.train() \n",
    "\n",
    "        # 1. Forward pass\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "\n",
    "        # 4. Loss backward\n",
    "\n",
    "        # 5. Optimizer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff3b47-c481-4edb-97b8-863b04f78bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
