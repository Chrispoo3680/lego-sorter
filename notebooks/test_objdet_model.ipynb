{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu118\n"
     ]
    }
   ],
   "source": [
    "# Download dependencies\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import has_file_allowed_extension, default_loader\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "\n",
    "import effdet\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from src.common import tools\n",
    "from src.common.tools import get_part_cat\n",
    "from src.classification.model import model\n",
    "\n",
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data\n",
    "data_path = Path(\"../data/obj_detection\")\n",
    "obj_detection_image_path = data_path / \"b200-lego-detection-dataset\"\n",
    "\n",
    "annot_dir = obj_detection_image_path / \"annotations\"\n",
    "image_dir = obj_detection_image_path / \"images\"\n",
    "\n",
    "\"\"\"\n",
    "classification_image_paths: List[Path] = []\n",
    "for root, dirs, _ in os.walk(data_path):\n",
    "    for dir_name in dirs:\n",
    "        folder_path: str = os.path.join(root, dir_name)\n",
    "        subfolder_contents: List[str] = os.listdir(folder_path)\n",
    "\n",
    "        if all(\n",
    "            os.path.isfile(os.path.join(folder_path, item))\n",
    "            for item in subfolder_contents\n",
    "        ):\n",
    "            classification_image_paths.append(Path(root))\n",
    "            break\n",
    "\"\"\"\n",
    "\n",
    "part_to_cat_path = Path(\"../src/data/parts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path) -> str:\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name(annotations, name_transform):\n",
    "    for part in annotations:\n",
    "        part[\"target\"] = name_transform(part[\"name\"])\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "from numpy import dtype, ndarray\n",
    "\n",
    "\n",
    "class LegoObjDetDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        image_dir: Union[str, Path], \n",
    "        annot_dir: Union[str, Path], \n",
    "        transform: Optional[Callable] = None, \n",
    "        target_transform: Optional[Callable] = lambda x: x, \n",
    "        loader: Callable[[str], Any] = default_loader\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        annotations = self.get_annotations(annot_dir, extensions=\".xml\")\n",
    "        classes, class_to_idx = self.find_classes(list(annotations.values()))\n",
    "        samples = self.make_dataset(annotations=annotations, image_dir=image_dir, class_to_idx=class_to_idx, extensions=\".png\")\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.annot_dir = annot_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.loader = loader\n",
    "\n",
    "        self.annotations = annotations\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "        self.samples = samples\n",
    "        self.labels = [s[1][\"labels\"] for s in samples]\n",
    "        self.bndboxes = [s[1][\"bndboxes\"] for s in samples]\n",
    "        self.images = [s[0] for s in samples]\n",
    "\n",
    "        if target_transform is not None:\n",
    "            self.transformed_to_idx = {transformed: idx for idx, transformed in enumerate(set(target_transform({\"labels\": [class_to_idx[_class] for _class in classes]}, class_to_idx)[\"labels\"]))}\n",
    "    \n",
    "\n",
    "    def get_annotations(\n",
    "        self,\n",
    "        annot_dir: Union[str, Path], \n",
    "        extensions: Optional[str] = None,\n",
    "        is_valid_file: Optional[Callable[[str], bool]] = None, # type: ignore\n",
    "    ) -> Dict[str, ndarray[Dict[str, Any], dtype[Any]]]:\n",
    "        \"\"\"Gets the image annotations from the annotation files.\n",
    "\n",
    "        Args:\n",
    "            annot_dir (Union[str, Path]): Path to directory that contains annotation files.\n",
    "            extensions (Optional[str], optional): Valid file extensions for annotation files. Defaults to None.\n",
    "            is_valid_file (Optional[Callable[[str], bool]], optional): Callable for checking is file is valid. Defaults to None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Both extensions and is_valid_file cannot be None or not None at the same time.\n",
    "            FileNotFoundError: Couldn't find any valid annotations files in directory.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, ndarray[Dict[str, Any], dtype[Any]]]: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        ann_dir = os.path.expanduser(annot_dir)\n",
    "\n",
    "        both_none = extensions is None and is_valid_file is None\n",
    "        both_something = extensions is not None and is_valid_file is not None\n",
    "        if both_none or both_something:\n",
    "            raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time.\")\n",
    "\n",
    "        if extensions is not None:\n",
    "\n",
    "            def is_valid_file(x: str) -> bool:\n",
    "                return has_file_allowed_extension(x, extensions)\n",
    "\n",
    "        annotations: Dict[str, ndarray[Dict[str, Any], dtype[Any]]] = {}\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(ann_dir)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                if is_valid_file(path): # type: ignore\n",
    "                    objects: ndarray[Dict[str, Any], dtype[Any]] = np.squeeze(\n",
    "                        list(xmltodict.parse(read_file(os.path.join(root, fname)))[\"annotations\"][\"object\"])\n",
    "                    )\n",
    "                    file_name = Path(path).stem\n",
    "                    annotations.update({file_name: objects})\n",
    "\n",
    "        if not annotations:\n",
    "            raise FileNotFoundError(f\"Couldn't find any valid annotations files in directory: {ann_dir}.\")\n",
    "\n",
    "        return annotations\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def find_classes(annotations: List[ndarray[Dict[str, Any], dtype[Any]]]) -> Tuple[List[str], Dict[str, int]]:\n",
    "        \"\"\"Finds the target classes in image annotation files.\n",
    "\n",
    "        Args:\n",
    "            annotations (ndarray[ndarray[Dict[str, Any], dtype[Any]], dtype[Any]]): Dictionary that contains annotations for alle image files.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: Couldn't find any classes in given annotations.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[str], Dict[str, int]]: Tuple that contains list with classes and dictionary for converting classes to respective indexes.\n",
    "        \"\"\"\n",
    "\n",
    "        classes: List[str] = sorted(set(target[\"name\"] for file in annotations for target in file))\n",
    "\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any classes in given annotations.\")\n",
    "\n",
    "        class_to_idx: Dict[str, int] = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "        return classes, class_to_idx\n",
    "\n",
    "\n",
    "    def make_dataset(\n",
    "        self,\n",
    "        annotations: Dict[str, ndarray[Dict[str, Any], dtype[Any]]],\n",
    "        image_dir: Union[str, Path],\n",
    "        class_to_idx: Optional[Dict[str, int]] = None,\n",
    "        extensions: Optional[str] = None,\n",
    "        is_valid_file: Optional[Callable[[str], bool]] = None, # type: ignore\n",
    "    ) -> List[Tuple[str, Dict[str, Union[List[int], List[List[int]]]]]]:\n",
    "        \"\"\"Makes a list with all images and the corresponding targets and bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            annotations (Dict[str, ndarray[Dict[str, Any], dtype[Any]]]): Dictionary that contains annotations for alle image files.\n",
    "            image_dir (Union[str, Path]): Path to directory that contain image files.\n",
    "            class_to_idx (Optional[Dict[str, int]], optional): Dictionary for converting classes to respective index. Defaults to None.\n",
    "            extensions (Optional[str], optional): Valid file name extensions for image files. Defaults to None.\n",
    "            is_valid_file (Optional[Callable[[str], bool]], optional): Callable for checking if file is valid as image file. Defaults to None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: 'class_to_index' must have at least one entry to collect any samples.\n",
    "            ValueError: Both extensions and is_valid_file cannot be None or not None at the same time.\n",
    "            FileNotFoundError: Couldn't find any valid image files in directory.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, List[int], List[List[int]]]]: List of samples that contains an image path and its annotations\n",
    "        \"\"\"\n",
    "\n",
    "        img_dir = os.path.expanduser(image_dir)\n",
    "\n",
    "        if class_to_idx is None:\n",
    "            _, class_to_idx = self.find_classes(annotations)\n",
    "        elif not class_to_idx:\n",
    "            raise ValueError(\n",
    "                \"'class_to_index' must have at least one entry to collect any samples.\"\n",
    "            )\n",
    "        \n",
    "        both_none = extensions is None and is_valid_file is None\n",
    "        both_something = extensions is not None and is_valid_file is not None\n",
    "        if both_none or both_something:\n",
    "            raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time.\")\n",
    "\n",
    "        if extensions is not None:\n",
    "\n",
    "            def is_valid_file(x: str) -> bool:\n",
    "                return has_file_allowed_extension(x, extensions)\n",
    "        \n",
    "            \n",
    "        instances = []\n",
    "        for root, _, fnames in sorted(os.walk(img_dir)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                if is_valid_file(path): # type: ignore\n",
    "                    target: ndarray[Dict[str, Any], dtype[Any]] = annotations[Path(fname).stem]\n",
    "                    item: Tuple[str, Dict[str, Union[List[int], List[List[int]]]]] = path, {\"labels\": [class_to_idx[obj[\"name\"]] for obj in target], \"bndboxes\": [[int(coor) for coor in obj[\"bndbox\"].values()] for obj in target]}\n",
    "                    instances.append(item)\n",
    "\n",
    "        if not instances:\n",
    "            raise FileNotFoundError(f\"Couldn't find any valid image files in directory: {img_dir}.\")\n",
    "        \n",
    "        return instances\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        class_to_idx = self.class_to_idx\n",
    "        \n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target, class_to_idx)\n",
    "            target[\"labels\"] = [self.transformed_to_idx[label] for label in target[\"labels\"]]\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_df = pd.read_csv(part_to_cat_path, sep=\",\")\n",
    "\n",
    "part_nums = part_df[\"part_num\"].to_numpy()\n",
    "part_cat_ids = part_df[\"part_cat_id\"].to_numpy()\n",
    "\n",
    "num_to_cat = {num: cat for num, cat in zip(part_nums, part_cat_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targ_trans(targets: Dict[str, Union[List[int], List[List[int]]]], class_to_idx):\n",
    "    targets_copy = targets.copy()\n",
    "    idx_to_class = {idx: _class for _class, idx in class_to_idx.items()}\n",
    "    targets_copy[\"labels\"] = [get_part_cat(part_id=idx_to_class[label], id_to_cat=num_to_cat) for label in targets_copy[\"labels\"]]\n",
    "    return targets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "objdet_dataset = LegoObjDetDataset(image_dir=image_dir, annot_dir=annot_dir, transform=image_transform, target_transform=targ_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sample size: torch.Size([3, 2048, 2048]), \\n'\n",
      " \"Target: {'labels': [4, 4, 18, 18, 1, 1, 7, 7, 23, 23, 4, 4, 4, 4, 19, 19, 4, \"\n",
      " '4, 11, 11, 25, 25, 19, 19, 4, 4, 6, 6, 15, 15, 26, 26, 8, 8, 4, 4, 8, 8, 23, '\n",
      " '23, 6, 6, 4, 4, 4, 4, 8, 8, 0, 0, 1, 1, 5, 5, 8, 8, 7, 7, 19, 19, 25, 25, '\n",
      " '11, 11, 8, 8, 4, 4, 7, 7, 21, 21, 5, 5, 5, 5, 17, 17, 25, 25, 4, 4, 4, 4, '\n",
      " '13, 13, 21, 21, 11, 11, 1, 1, 23, 23, 25, 25, 0, 0, 1, 1, 5, 5, 5, 5, 5, 5, '\n",
      " '5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, '\n",
      " '7, 7, 7, 7, 7, 0, 0, 18, 18, 0, 0, 0, 0, 14, 14, 1, 1, 12, 12, 5, 5, 11, 11, '\n",
      " '11, 11, 11, 11, 3, 3, 6, 6, 4, 4, 23, 23, 20, 20, 3, 3, 20, 20, 24, 24, 22, '\n",
      " '22, 6, 6, 22, 22, 22, 22, 5, 5, 22, 22, 22, 22, 22, 22, 22, 22, 17, 17, 1, '\n",
      " '1, 17, 17, 4, 4, 4, 4, 7, 7, 4, 4, 5, 5, 7, 7, 0, 0, 0, 0, 7, 7, 23, 23, 3, '\n",
      " '3, 3, 3, 20, 20, 7, 7, 24, 24, 23, 23, 7, 7, 7, 7, 10, 10, 12, 12, 7, 7, 13, '\n",
      " '13, 22, 22, 1, 1, 13, 13, 4, 4, 4, 4, 11, 11, 22, 22, 4, 4, 21, 21, 21, 21, '\n",
      " '6, 6, 23, 23, 0, 0, 23, 23, 21, 21, 21, 21, 4, 4, 7, 7, 20, 20, 12, 12, 16, '\n",
      " '16, 13, 13, 19, 19, 4, 4, 14, 14, 18, 18, 4, 4, 19, 19, 21, 21, 17, 17, 0, '\n",
      " '0, 6, 6, 4, 4, 13, 13, 4, 4, 7, 7, 0, 0, 22, 22, 9, 9, 9, 9, 19, 19, 4, 4, '\n",
      " '10, 10, 0, 0, 19, 19, 6, 6, 11, 11, 4, 4, 18, 18, 16, 16, 6, 6, 3, 3, 23, '\n",
      " '23, 22, 22, 11, 11, 12, 12, 13, 13, 0, 0, 11, 11, 20, 20, 1, 1, 14, 14, 4, '\n",
      " '4, 2, 2, 18, 18, 4, 4, 15, 15, 4, 4, 0, 0, 19, 19, 25, 25, 1, 1, 4, 4, 4, 4, '\n",
      " \"8, 8, 4, 4, 4, 4, 10, 10, 10, 10], 'bndboxes': [[850, 1582, 909, 1643], \"\n",
      " '[820, 1201, 873, 1257], [349, 243, 372, 285], [1453, 977, 1488, 1012], '\n",
      " '[1160, 1077, 1207, 1113], [524, 793, 562, 841], [959, 714, 1045, 801], '\n",
      " '[1063, 751, 1151, 840], [1257, 387, 1277, 454], [1428, 756, 1490, 797], '\n",
      " '[1189, 1431, 1233, 1471], [44, 892, 84, 937], [1924, 993, 1974, 1036], '\n",
      " '[1309, 1599, 1353, 1648], [1043, 1589, 1088, 1616], [702, 609, 737, 656], '\n",
      " '[1097, 386, 1144, 435], [1387, 1493, 1433, 1542], [1446, 1261, 1494, 1318], '\n",
      " '[1779, 1790, 1828, 1850], [1398, 1101, 1441, 1142], [1876, 1947, 1919, '\n",
      " '1992], [1597, 350, 1653, 405], [1138, 222, 1196, 283], [689, 1338, 724, '\n",
      " '1370], [1458, 670, 1491, 702], [34, 1274, 83, 1303], [973, 1356, 998, 1390], '\n",
      " '[549, 926, 584, 981], [1188, 1092, 1233, 1141], [1365, 441, 1384, 473], [43, '\n",
      " '444, 73, 464], [709, 414, 751, 458], [460, 1413, 502, 1456], [1257, 1587, '\n",
      " '1304, 1628], [1651, 386, 1688, 434], [654, 1556, 684, 1587], [80, 863, 110, '\n",
      " '889], [1019, 1044, 1035, 1107], [1314, 380, 1375, 424], [461, 1841, 487, '\n",
      " '1866], [1939, 1179, 1964, 1203], [1171, 1036, 1213, 1078], [1258, 59, 1300, '\n",
      " '108], [1264, 440, 1310, 470], [904, 857, 937, 903], [1414, 769, 1436, 791], '\n",
      " '[41, 425, 67, 446], [765, 250, 791, 277], [51, 872, 74, 899], [837, 1486, '\n",
      " '887, 1538], [818, 1400, 878, 1463], [1190, 1491, 1238, 1553], [856, 776, '\n",
      " '912, 826], [203, 668, 249, 714], [1876, 1564, 1924, 1592], [1820, 1821, '\n",
      " '1868, 1883], [1360, 984, 1418, 1030], [893, 126, 933, 173], [47, 1303, 84, '\n",
      " '1349], [1269, 1417, 1294, 1442], [762, 292, 785, 317], [1118, 1222, 1170, '\n",
      " '1307], [924, 1809, 994, 1888], [988, 1008, 1038, 1061], [493, 570, 541, '\n",
      " '621], [826, 157, 911, 210], [327, 1087, 418, 1120], [498, 1504, 740, 1655], '\n",
      " '[681, 112, 830, 357], [750, 506, 831, 574], [540, 1273, 607, 1353], [1817, '\n",
      " '1232, 1960, 1314], [79, 1263, 221, 1353], [130, 744, 260, 856], [502, 1603, '\n",
      " '641, 1699], [872, 676, 892, 696], [1419, 1659, 1439, 1681], [1332, 284, '\n",
      " '1361, 308], [1960, 756, 1985, 784], [1795, 1944, 1840, 1994], [151, 1059, '\n",
      " '207, 1107], [667, 1737, 695, 1777], [841, 460, 880, 493], [546, 101, 585, '\n",
      " '138], [1232, 345, 1273, 391], [1298, 1313, 1345, 1370], [1412, 808, 1472, '\n",
      " '854], [1921, 906, 1992, 956], [772, 673, 841, 748], [1440, 1923, 1475, '\n",
      " '1959], [910, 791, 945, 825], [1684, 375, 1702, 422], [1088, 1045, 1131, '\n",
      " '1077], [1214, 76, 1258, 121], [1736, 1127, 1783, 1168], [1259, 1774, 1307, '\n",
      " '1828], [1965, 1937, 2009, 1993], [1471, 820, 1523, 859], [585, 1656, 629, '\n",
      " '1711], [1115, 1084, 1193, 1179], [1676, 1391, 1780, 1468], [303, 31, 380, '\n",
      " '121], [1649, 270, 1731, 338], [1642, 1139, 1707, 1195], [783, 1004, 836, '\n",
      " '1054], [1872, 76, 1930, 122], [1428, 1731, 1480, 1788], [1186, 1260, 1212, '\n",
      " '1293], [1070, 1665, 1101, 1697], [563, 1874, 727, 1983], [794, 602, 963, '\n",
      " '665], [1506, 565, 1618, 677], [1348, 1836, 1478, 1918], [1223, 1028, 1311, '\n",
      " '1091], [1430, 1617, 1487, 1712], [1184, 1366, 1227, 1399], [646, 598, 694, '\n",
      " '649], [748, 586, 801, 675], [49, 498, 114, 590], [1375, 1893, 1448, 1980], '\n",
      " '[320, 737, 386, 780], [1219, 1392, 1265, 1439], [506, 980, 565, 1037], '\n",
      " '[1301, 110, 1338, 162], [890, 472, 933, 488], [1362, 945, 1391, 973], [1625, '\n",
      " '750, 1654, 777], [733, 787, 829, 882], [1485, 1271, 1604, 1389], [993, 1083, '\n",
      " '1141, 1213], [1267, 610, 1412, 759], [1497, 1408, 1619, 1573], [43, 1051, '\n",
      " '213, 1167], [1656, 841, 1831, 927], [1378, 59, 1488, 233], [314, 654, 404, '\n",
      " '740], [881, 704, 956, 796], [47, 967, 70, 1050], [1911, 372, 1922, 458], '\n",
      " '[799, 1925, 858, 1994], [888, 652, 946, 710], [945, 691, 981, 743], [538, '\n",
      " '56, 589, 110], [810, 1253, 897, 1304], [662, 1456, 688, 1547], [233, 1172, '\n",
      " '319, 1250], [354, 1534, 444, 1610], [782, 1963, 807, 2001], [1373, 1200, '\n",
      " '1396, 1231], [742, 453, 790, 508], [1948, 706, 1999, 757], [1039, 1488, '\n",
      " '1089, 1540], [1711, 589, 1771, 648], [1613, 679, 1638, 723], [788, 571, 834, '\n",
      " '605], [1113, 1561, 1142, 1592], [1278, 105, 1306, 136], [502, 1150, 543, '\n",
      " '1198], [1715, 171, 1769, 230], [1689, 545, 1716, 592], [138, 285, 187, 315], '\n",
      " '[967, 61, 1014, 118], [1724, 296, 1778, 349], [1681, 1264, 1739, 1317], '\n",
      " '[697, 654, 756, 705], [231, 1324, 277, 1349], [625, 1313, 658, 1354], [616, '\n",
      " '502, 670, 553], [618, 1526, 671, 1573], [1257, 468, 1362, 481], [1140, 1228, '\n",
      " '1199, 1324], [592, 1114, 614, 1134], [1736, 1328, 1759, 1347], [937, 1171, '\n",
      " '1007, 1244], [917, 388, 991, 464], [1166, 1006, 1229, 1040], [921, 329, 982, '\n",
      " '384], [360, 589, 476, 890], [40, 1573, 105, 1884], [742, 692, 773, 797], '\n",
      " '[1014, 1676, 1071, 1778], [192, 1443, 265, 1513], [670, 443, 720, 505], '\n",
      " '[1472, 1975, 1534, 2008], [1312, 1054, 1359, 1107], [1365, 119, 1483, 236], '\n",
      " '[1258, 731, 1342, 867], [1513, 708, 1661, 905], [340, 1199, 563, 1288], '\n",
      " '[516, 396, 622, 478], [1338, 1300, 1400, 1415], [206, 432, 247, 476], [619, '\n",
      " '900, 660, 921], [1230, 1004, 1280, 1034], [1468, 1234, 1520, 1262], [1722, '\n",
      " '1096, 1747, 1115], [1688, 1970, 1709, 1997], [1337, 1868, 1397, 1927], [192, '\n",
      " '1767, 254, 1829], [990, 927, 1016, 991], [287, 950, 324, 1015], [716, 1465, '\n",
      " '847, 1592], [1192, 1683, 1279, 1847], [1105, 1172, 1146, 1197], [264, 895, '\n",
      " '294, 937], [1762, 225, 1822, 302], [1865, 1336, 1927, 1407], [1231, 984, '\n",
      " '1297, 1014], [1845, 929, 1878, 994], [1468, 215, 1521, 268], [1557, 172, '\n",
      " '1616, 235], [274, 840, 324, 888], [1930, 327, 1969, 381], [1363, 830, 1454, '\n",
      " '943], [245, 1122, 343, 1232], [442, 171, 486, 207], [1247, 257, 1291, 283], '\n",
      " '[956, 422, 1006, 474], [157, 1022, 214, 1058], [1652, 731, 1697, 820], '\n",
      " '[1566, 732, 1654, 807], [1159, 827, 1241, 864], [576, 1034, 634, 1108], '\n",
      " '[1423, 1315, 1482, 1399], [1459, 316, 1546, 368], [591, 1088, 617, 1115], '\n",
      " '[987, 1207, 1011, 1233], [1334, 124, 1377, 157], [1579, 969, 1616, 1009], '\n",
      " '[541, 1372, 613, 1504], [1675, 746, 1803, 853], [1760, 1084, 1975, 1159], '\n",
      " '[683, 1485, 863, 1658], [883, 1645, 931, 1691], [63, 271, 117, 299], [1606, '\n",
      " '1881, 1653, 1939], [628, 1425, 672, 1476], [1003, 1327, 1168, 1492], [81, '\n",
      " '1632, 256, 1807], [1728, 697, 1771, 740], [51, 351, 99, 396], [1704, 40, '\n",
      " '1899, 74], [1354, 1444, 1397, 1631], [1185, 1545, 1218, 1577], [714, 1371, '\n",
      " '744, 1407], [341, 1180, 361, 1200], [296, 925, 319, 945], [1321, 1954, 1341, '\n",
      " '2004], [105, 522, 152, 547], [554, 1105, 575, 1142], [488, 290, 511, 329], '\n",
      " '[1383, 920, 1482, 1075], [1735, 755, 1887, 865], [1564, 1699, 1606, 1726], '\n",
      " '[834, 1293, 867, 1330], [232, 927, 287, 1011], [1270, 1415, 1355, 1468], '\n",
      " '[1479, 46, 1564, 92], [1096, 198, 1138, 287], [1317, 1445, 1372, 1532], '\n",
      " '[1029, 820, 1113, 893], [1156, 671, 1196, 733], [410, 805, 469, 854], [1428, '\n",
      " '1022, 1449, 1050], [1430, 43, 1455, 73], [1267, 1704, 1337, 1748], [601, '\n",
      " '344, 641, 411], [1075, 1189, 1114, 1227], [437, 232, 456, 281], [913, 1412, '\n",
      " '979, 1470], [691, 1304, 764, 1345], [1147, 1274, 1206, 1349], [1380, 938, '\n",
      " '1448, 1002], [832, 259, 888, 318], [1622, 422, 1676, 476], [1810, 818, 1857, '\n",
      " '1026], [1280, 1373, 1340, 1577], [1943, 469, 1984, 531], [198, 1563, 215, '\n",
      " '1629], [252, 733, 286, 757], [42, 60, 66, 96], [634, 1499, 663, 1533], '\n",
      " '[1213, 1275, 1243, 1304], [1401, 1321, 1419, 1363], [1714, 738, 1756, 779], '\n",
      " '[1935, 1356, 1987, 1406], [1326, 83, 1372, 131], [1346, 1634, 1388, 1683], '\n",
      " '[1555, 1209, 1613, 1263], [852, 102, 904, 154], [1699, 937, 1754, 988], '\n",
      " '[685, 1035, 722, 1063], [1786, 951, 1816, 988], [1380, 1752, 1424, 1777], '\n",
      " '[749, 57, 791, 85], [1022, 312, 1088, 345], [1217, 310, 1280, 358], [137, '\n",
      " '755, 214, 827], [1865, 932, 1929, 1009], [519, 1294, 550, 1322], [306, 1537, '\n",
      " '347, 1548], [1179, 525, 1207, 552], [1585, 1465, 1614, 1494], [41, 1954, 78, '\n",
      " '2006], [950, 773, 981, 819], [1363, 764, 1408, 810], [545, 1693, 595, 1745], '\n",
      " '[637, 353, 721, 439], [1765, 949, 1854, 1032], [141, 965, 178, 1026], [1214, '\n",
      " '788, 1249, 849], [946, 693, 1161, 853], [845, 1680, 880, 1939], [172, 220, '\n",
      " '237, 287], [1798, 1736, 1850, 1802], [1535, 1551, 1581, 1584], [1147, 1182, '\n",
      " '1172, 1223], [1170, 689, 1230, 756], [1378, 1956, 1436, 2011], [1846, 1646, '\n",
      " '1891, 1692], [208, 1624, 260, 1675], [664, 778, 716, 813], [828, 482, 864, '\n",
      " '533], [1102, 1546, 1138, 1577], [1961, 1078, 2004, 1114], [1537, 1651, 1588, '\n",
      " '1702], [1029, 1024, 1087, 1082], [1468, 606, 1516, 646], [742, 1895, 765, '\n",
      " '1945], [323, 936, 355, 1024], [579, 1477, 665, 1518], [841, 1066, 883, '\n",
      " '1108], [920, 379, 961, 424], [1048, 1361, 1076, 1426], [1429, 1781, 1466, '\n",
      " '1849], [1259, 1454, 1292, 1514], [1960, 50, 2002, 111], [1352, 1013, 1370, '\n",
      " '1138], [492, 1425, 522, 1550], [1515, 1205, 1549, 1252], [43, 1690, 66, '\n",
      " '1742], [1962, 160, 2005, 206], [1358, 1926, 1387, 1976], [909, 1274, 937, '\n",
      " '1308], [1011, 71, 1044, 112], [1002, 794, 1063, 834], [1210, 1260, 1274, '\n",
      " '1279], [1752, 1838, 1779, 1903], [1202, 349, 1234, 411], [1955, 1188, 2001, '\n",
      " '1315], [1816, 994, 1889, 1114], [1009, 1654, 1066, 1709], [597, 767, 638, '\n",
      " '829], [878, 1158, 898, 1176], [245, 652, 267, 673], [823, 1051, 848, 1093], '\n",
      " '[774, 1731, 818, 1782], [1227, 276, 1319, 345], [1624, 1761, 1716, 1849], '\n",
      " '[425, 1549, 506, 1599], [1038, 1948, 1122, 1972], [1529, 384, 1560, 414], '\n",
      " '[1496, 79, 1533, 123], [1391, 1272, 1456, 1328], [664, 682, 725, 733], '\n",
      " '[1305, 1529, 1355, 1580], [1232, 1075, 1280, 1122], [639, 162, 686, 224], '\n",
      " '[1732, 1905, 1782, 1968], [48, 779, 72, 841], [296, 1292, 344, 1344], [937, '\n",
      " '1680, 978, 1730], [689, 1547, 733, 1596], [884, 511, 932, 612], [37, 1115, '\n",
      " '123, 1212], [556, 1057, 589, 1102], [475, 678, 515, 724], [1196, 963, 1242, '\n",
      " '1003], [664, 649, 700, 690], [1755, 1347, 1825, 1424], [1442, 214, 1480, '\n",
      " '300], [1426, 1324, 1448, 1346], [1943, 171, 1968, 195], [1950, 946, 2010, '\n",
      " '991], [1670, 438, 1726, 485], [814, 729, 865, 784], [656, 1656, 704, 1706], '\n",
      " '[1269, 938, 1329, 1000], [465, 1573, 523, 1640], [946, 933, 979, 979], [798, '\n",
      " '188, 826, 233], [246, 783, 275, 829], [1858, 301, 1908, 355], [110, 1035, '\n",
      " '152, 1083], [1522, 75, 1575, 126], [618, 1371, 655, 1421], [582, 1332, 622, '\n",
      " '1381], [997, 45, 1047, 80], [829, 1871, 860, 1927]]}')\n"
     ]
    }
   ],
   "source": [
    "sample, target = objdet_dataset[0]\n",
    "pprint(f\"Sample size: {sample.size()}, \\nTarget: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0,\n",
       " 5: 1,\n",
       " 6: 2,\n",
       " 8: 3,\n",
       " 9: 4,\n",
       " 11: 5,\n",
       " 12: 6,\n",
       " 14: 7,\n",
       " 15: 8,\n",
       " 16: 9,\n",
       " 18: 10,\n",
       " 19: 11,\n",
       " 20: 12,\n",
       " 21: 13,\n",
       " 23: 14,\n",
       " 26: 15,\n",
       " 27: 16,\n",
       " 28: 17,\n",
       " 32: 18,\n",
       " 37: 19,\n",
       " 46: 20,\n",
       " 49: 21,\n",
       " 51: 22,\n",
       " 53: 23,\n",
       " 54: 24,\n",
       " 67: 25,\n",
       " 68: 26}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objdet_dataset.transformed_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "EfficientNet (EfficientNet)                        [64, 3, 512, 512]    [64, 200]            --                   True\n",
       "├─Conv2d (conv_stem)                               [64, 3, 512, 512]    [64, 32, 256, 256]   864                  True\n",
       "├─BatchNormAct2d (bn1)                             [64, 32, 256, 256]   [64, 32, 256, 256]   64                   True\n",
       "│    └─Identity (drop)                             [64, 32, 256, 256]   [64, 32, 256, 256]   --                   --\n",
       "│    └─SiLU (act)                                  [64, 32, 256, 256]   [64, 32, 256, 256]   --                   --\n",
       "├─Sequential (blocks)                              [64, 32, 256, 256]   [64, 320, 16, 16]    --                   True\n",
       "│    └─Sequential (0)                              [64, 32, 256, 256]   [64, 16, 256, 256]   --                   True\n",
       "│    │    └─DepthwiseSeparableConv (0)             [64, 32, 256, 256]   [64, 16, 256, 256]   1,448                True\n",
       "│    └─Sequential (1)                              [64, 16, 256, 256]   [64, 24, 128, 128]   --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 16, 256, 256]   [64, 24, 128, 128]   6,004                True\n",
       "│    │    └─InvertedResidual (1)                   [64, 24, 128, 128]   [64, 24, 128, 128]   10,710               True\n",
       "│    └─Sequential (2)                              [64, 24, 128, 128]   [64, 40, 64, 64]     --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 24, 128, 128]   [64, 40, 64, 64]     15,350               True\n",
       "│    │    └─InvertedResidual (1)                   [64, 40, 64, 64]     [64, 40, 64, 64]     31,290               True\n",
       "│    └─Sequential (3)                              [64, 40, 64, 64]     [64, 80, 32, 32]     --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 40, 64, 64]     [64, 80, 32, 32]     37,130               True\n",
       "│    │    └─InvertedResidual (1)                   [64, 80, 32, 32]     [64, 80, 32, 32]     102,900              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 80, 32, 32]     [64, 80, 32, 32]     102,900              True\n",
       "│    └─Sequential (4)                              [64, 80, 32, 32]     [64, 112, 32, 32]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 80, 32, 32]     [64, 112, 32, 32]    126,004              True\n",
       "│    │    └─InvertedResidual (1)                   [64, 112, 32, 32]    [64, 112, 32, 32]    208,572              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 112, 32, 32]    [64, 112, 32, 32]    208,572              True\n",
       "│    └─Sequential (5)                              [64, 112, 32, 32]    [64, 192, 16, 16]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 112, 32, 32]    [64, 192, 16, 16]    262,492              True\n",
       "│    │    └─InvertedResidual (1)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    │    └─InvertedResidual (3)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    └─Sequential (6)                              [64, 192, 16, 16]    [64, 320, 16, 16]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 192, 16, 16]    [64, 320, 16, 16]    717,232              True\n",
       "├─Conv2d (conv_head)                               [64, 320, 16, 16]    [64, 1280, 16, 16]   409,600              True\n",
       "├─BatchNormAct2d (bn2)                             [64, 1280, 16, 16]   [64, 1280, 16, 16]   2,560                True\n",
       "│    └─Identity (drop)                             [64, 1280, 16, 16]   [64, 1280, 16, 16]   --                   --\n",
       "│    └─SiLU (act)                                  [64, 1280, 16, 16]   [64, 1280, 16, 16]   --                   --\n",
       "├─SelectAdaptivePool2d (global_pool)               [64, 1280, 16, 16]   [64, 1280]           --                   --\n",
       "│    └─AdaptiveAvgPool2d (pool)                    [64, 1280, 16, 16]   [64, 1280, 1, 1]     --                   --\n",
       "│    └─Flatten (flatten)                           [64, 1280, 1, 1]     [64, 1280]           --                   --\n",
       "├─Sequential (classifier)                          [64, 1280]           [64, 200]            --                   True\n",
       "│    └─Dropout (0)                                 [64, 1280]           [64, 1280]           --                   --\n",
       "│    └─Linear (1)                                  [64, 1280]           [64, 200]            256,200              True\n",
       "==================================================================================================================================\n",
       "Total params: 4,263,748\n",
       "Trainable params: 4,263,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 128.42\n",
       "==================================================================================================================================\n",
       "Input size (MB): 201.33\n",
       "Forward/backward pass size (MB): 18027.81\n",
       "Params size (MB): 16.89\n",
       "Estimated Total Size (MB): 18246.02\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#effnet_classifier, _ = create_efficientnet_b0(class_names=torch.zeros(37), device=device)\n",
    "effnet_classifier = timm.create_model('efficientnet_b0', pretrained=True).to(device)\n",
    "\n",
    "frozen_blocks = [0, 1, 2, 3]\n",
    "\"\"\"\n",
    "for idx in frozen_blocks:\n",
    "    for param in effnet_classifier.blocks[idx].parameters():\n",
    "        param.requires_grad = False\n",
    "\"\"\"\n",
    "input_shape = effnet_classifier.classifier.in_features\n",
    "output_shape = 200\n",
    "\n",
    "effnet_classifier.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(\n",
    "            in_features=input_shape,\n",
    "            out_features=output_shape,\n",
    "            bias=True,\n",
    "        ),\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "summary(model=effnet_classifier, \n",
    "        input_size=(64, 3, 512, 512), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [64, 3, 224, 224]    [64, 200]            --                   True\n",
       "├─Sequential (features)                                      [64, 3, 224, 224]    [64, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [64, 3, 224, 224]    [64, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [64, 3, 224, 224]    [64, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [64, 32, 112, 112]   [64, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [64, 32, 112, 112]   [64, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [64, 32, 112, 112]   [64, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 32, 112, 112]   [64, 16, 112, 112]   1,448                True\n",
       "│    └─Sequential (2)                                        [64, 16, 112, 112]   [64, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 16, 112, 112]   [64, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [64, 24, 56, 56]     [64, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [64, 24, 56, 56]     [64, 40, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 24, 56, 56]     [64, 40, 28, 28]     15,350               True\n",
       "│    │    └─MBConv (1)                                       [64, 40, 28, 28]     [64, 40, 28, 28]     31,290               True\n",
       "│    └─Sequential (4)                                        [64, 40, 28, 28]     [64, 80, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 40, 28, 28]     [64, 80, 14, 14]     37,130               True\n",
       "│    │    └─MBConv (1)                                       [64, 80, 14, 14]     [64, 80, 14, 14]     102,900              True\n",
       "│    │    └─MBConv (2)                                       [64, 80, 14, 14]     [64, 80, 14, 14]     102,900              True\n",
       "│    └─Sequential (5)                                        [64, 80, 14, 14]     [64, 112, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 80, 14, 14]     [64, 112, 14, 14]    126,004              True\n",
       "│    │    └─MBConv (1)                                       [64, 112, 14, 14]    [64, 112, 14, 14]    208,572              True\n",
       "│    │    └─MBConv (2)                                       [64, 112, 14, 14]    [64, 112, 14, 14]    208,572              True\n",
       "│    └─Sequential (6)                                        [64, 112, 14, 14]    [64, 192, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 112, 14, 14]    [64, 192, 7, 7]      262,492              True\n",
       "│    │    └─MBConv (1)                                       [64, 192, 7, 7]      [64, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (2)                                       [64, 192, 7, 7]      [64, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (3)                                       [64, 192, 7, 7]      [64, 192, 7, 7]      587,952              True\n",
       "│    └─Sequential (7)                                        [64, 192, 7, 7]      [64, 320, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [64, 192, 7, 7]      [64, 320, 7, 7]      717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [64, 320, 7, 7]      [64, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [64, 320, 7, 7]      [64, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [64, 1280, 7, 7]     [64, 1280, 7, 7]     2,560                True\n",
       "│    │    └─SiLU (2)                                         [64, 1280, 7, 7]     [64, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [64, 1280, 7, 7]     [64, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [64, 1280]           [64, 200]            --                   True\n",
       "│    └─Dropout (0)                                           [64, 1280]           [64, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [64, 1280]           [64, 200]            256,200              True\n",
       "============================================================================================================================================\n",
       "Total params: 4,263,748\n",
       "Trainable params: 4,263,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 24.63\n",
       "============================================================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 6904.29\n",
       "Params size (MB): 17.05\n",
       "Estimated Total Size (MB): 6959.88\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet_classifier2 = torchvision.models.efficientnet_b0().to(device)\n",
    "\n",
    "input_shape = 1280\n",
    "output_shape = 200\n",
    "\n",
    "effnet_classifier2.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(\n",
    "            in_features=input_shape,\n",
    "            out_features=output_shape,\n",
    "            bias=True,\n",
    "        ),\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "summary(model=effnet_classifier2, \n",
    "        input_size=(64, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_24792\\890866467.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  effnet_sorter.load_state_dict(torch.load(f=\"../models/classification/batch_1/efficientnet_b0_lego_sorter.pt\"))\n"
     ]
    }
   ],
   "source": [
    "effnet_sorter, weights = model.create_efficientnet_b0(class_names=np.zeros(37), device=device)\n",
    "image_transform = weights.transforms()\n",
    "effnet_sorter.load_state_dict(torch.load(f=\"../models/classification/batch_1/efficientnet_b0_lego_sorter.pt\"))\n",
    "\n",
    "for param in effnet_sorter.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['conv_head.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effdet_model = effdet.create_model(\"tf_efficientdet_d0\", pretrained_backbone=False).to(device)\n",
    "effdet_model.backbone.load_state_dict(effnet_classifier.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "EfficientNet (EfficientNet)                        [64, 3, 512, 512]    [64, 200]            --                   True\n",
       "├─Conv2d (conv_stem)                               [64, 3, 512, 512]    [64, 32, 256, 256]   864                  True\n",
       "├─BatchNormAct2d (bn1)                             [64, 32, 256, 256]   [64, 32, 256, 256]   64                   True\n",
       "│    └─Identity (drop)                             [64, 32, 256, 256]   [64, 32, 256, 256]   --                   --\n",
       "│    └─SiLU (act)                                  [64, 32, 256, 256]   [64, 32, 256, 256]   --                   --\n",
       "├─Sequential (blocks)                              [64, 32, 256, 256]   [64, 320, 16, 16]    --                   True\n",
       "│    └─Sequential (0)                              [64, 32, 256, 256]   [64, 16, 256, 256]   --                   True\n",
       "│    │    └─DepthwiseSeparableConv (0)             [64, 32, 256, 256]   [64, 16, 256, 256]   1,448                True\n",
       "│    └─Sequential (1)                              [64, 16, 256, 256]   [64, 24, 128, 128]   --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 16, 256, 256]   [64, 24, 128, 128]   6,004                True\n",
       "│    │    └─InvertedResidual (1)                   [64, 24, 128, 128]   [64, 24, 128, 128]   10,710               True\n",
       "│    └─Sequential (2)                              [64, 24, 128, 128]   [64, 40, 64, 64]     --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 24, 128, 128]   [64, 40, 64, 64]     15,350               True\n",
       "│    │    └─InvertedResidual (1)                   [64, 40, 64, 64]     [64, 40, 64, 64]     31,290               True\n",
       "│    └─Sequential (3)                              [64, 40, 64, 64]     [64, 80, 32, 32]     --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 40, 64, 64]     [64, 80, 32, 32]     37,130               True\n",
       "│    │    └─InvertedResidual (1)                   [64, 80, 32, 32]     [64, 80, 32, 32]     102,900              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 80, 32, 32]     [64, 80, 32, 32]     102,900              True\n",
       "│    └─Sequential (4)                              [64, 80, 32, 32]     [64, 112, 32, 32]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 80, 32, 32]     [64, 112, 32, 32]    126,004              True\n",
       "│    │    └─InvertedResidual (1)                   [64, 112, 32, 32]    [64, 112, 32, 32]    208,572              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 112, 32, 32]    [64, 112, 32, 32]    208,572              True\n",
       "│    └─Sequential (5)                              [64, 112, 32, 32]    [64, 192, 16, 16]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 112, 32, 32]    [64, 192, 16, 16]    262,492              True\n",
       "│    │    └─InvertedResidual (1)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    │    └─InvertedResidual (2)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    │    └─InvertedResidual (3)                   [64, 192, 16, 16]    [64, 192, 16, 16]    587,952              True\n",
       "│    └─Sequential (6)                              [64, 192, 16, 16]    [64, 320, 16, 16]    --                   True\n",
       "│    │    └─InvertedResidual (0)                   [64, 192, 16, 16]    [64, 320, 16, 16]    717,232              True\n",
       "├─Conv2d (conv_head)                               [64, 320, 16, 16]    [64, 1280, 16, 16]   409,600              True\n",
       "├─BatchNormAct2d (bn2)                             [64, 1280, 16, 16]   [64, 1280, 16, 16]   2,560                True\n",
       "│    └─Identity (drop)                             [64, 1280, 16, 16]   [64, 1280, 16, 16]   --                   --\n",
       "│    └─SiLU (act)                                  [64, 1280, 16, 16]   [64, 1280, 16, 16]   --                   --\n",
       "├─SelectAdaptivePool2d (global_pool)               [64, 1280, 16, 16]   [64, 1280]           --                   --\n",
       "│    └─AdaptiveAvgPool2d (pool)                    [64, 1280, 16, 16]   [64, 1280, 1, 1]     --                   --\n",
       "│    └─Flatten (flatten)                           [64, 1280, 1, 1]     [64, 1280]           --                   --\n",
       "├─Sequential (classifier)                          [64, 1280]           [64, 200]            --                   True\n",
       "│    └─Dropout (0)                                 [64, 1280]           [64, 1280]           --                   --\n",
       "│    └─Linear (1)                                  [64, 1280]           [64, 200]            256,200              True\n",
       "==================================================================================================================================\n",
       "Total params: 4,263,748\n",
       "Trainable params: 4,263,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 128.42\n",
       "==================================================================================================================================\n",
       "Input size (MB): 201.33\n",
       "Forward/backward pass size (MB): 18027.81\n",
       "Params size (MB): 16.89\n",
       "Estimated Total Size (MB): 18246.02\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=effnet_classifier, \n",
    "        input_size=(64, 3, 512, 512), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[[[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5952,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5952,  ..., -4.5952, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5952, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5952, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5952, -4.5951,  ..., -4.5951, -4.5952, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5952, -4.5951,  ..., -4.5952, -4.5952, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5952, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5952, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5952, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>), tensor([[[[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>), tensor([[[[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>), tensor([[[[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          ...,\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951,  ..., -4.5951, -4.5951, -4.5951]]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>), tensor([[[[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]],\n",
      "\n",
      "         [[-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951],\n",
      "          [-4.5951, -4.5951, -4.5951, -4.5951]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>)], [tensor([[[[-1.0560e-05, -6.7144e-07, -3.8362e-05,  ...,  8.5651e-06,\n",
      "           -7.8471e-06,  1.2181e-06],\n",
      "          [ 9.1563e-06, -9.2559e-06, -3.1866e-05,  ..., -4.9850e-06,\n",
      "            8.5691e-06,  1.5664e-06],\n",
      "          [ 2.8435e-06,  2.0624e-05, -5.5179e-06,  ...,  4.9817e-06,\n",
      "            2.4915e-05, -1.9305e-05],\n",
      "          ...,\n",
      "          [-5.9699e-06, -1.1291e-05, -6.5006e-06,  ..., -2.0939e-05,\n",
      "           -2.2236e-05, -2.0356e-05],\n",
      "          [ 2.6126e-06,  3.3214e-06, -3.3824e-05,  ..., -1.9597e-06,\n",
      "            2.9213e-05, -9.8087e-06],\n",
      "          [-1.6750e-06,  7.2601e-06,  6.9900e-06,  ..., -1.1551e-05,\n",
      "           -3.7834e-06, -6.0682e-07]],\n",
      "\n",
      "         [[ 1.9171e-06,  3.1330e-06,  3.2447e-07,  ...,  1.9194e-05,\n",
      "            2.0337e-06,  4.8135e-06],\n",
      "          [-6.8271e-06, -2.1823e-05, -2.8672e-05,  ...,  1.3906e-05,\n",
      "            1.0530e-05, -1.0446e-05],\n",
      "          [-8.3143e-06,  2.0498e-06, -1.0829e-06,  ..., -1.5886e-05,\n",
      "           -6.9639e-06, -9.7515e-06],\n",
      "          ...,\n",
      "          [-4.5674e-06,  2.3134e-07,  1.3982e-05,  ...,  2.5097e-05,\n",
      "           -1.0481e-05,  9.8657e-07],\n",
      "          [-6.8482e-06, -9.3963e-06, -8.5707e-06,  ..., -2.9934e-06,\n",
      "            3.3488e-05, -1.7234e-05],\n",
      "          [-4.2045e-06,  1.6969e-05, -8.8448e-06,  ..., -1.4348e-05,\n",
      "           -1.8241e-07,  2.9734e-06]],\n",
      "\n",
      "         [[-1.1388e-05,  7.5446e-06,  5.6776e-06,  ...,  2.3840e-05,\n",
      "           -2.8168e-06,  1.4011e-05],\n",
      "          [ 1.3118e-05,  2.5364e-06, -3.3809e-06,  ...,  2.9343e-05,\n",
      "            2.2324e-06,  1.6408e-06],\n",
      "          [-7.9173e-06, -7.2388e-06, -4.4982e-06,  ..., -2.6975e-05,\n",
      "            1.5509e-05,  9.0160e-06],\n",
      "          ...,\n",
      "          [-1.5354e-05, -1.8059e-06,  3.5826e-05,  ..., -2.6436e-05,\n",
      "            6.9558e-06, -4.0323e-06],\n",
      "          [-1.6508e-05, -2.6303e-05, -1.1137e-05,  ...,  3.7203e-05,\n",
      "           -6.3888e-07,  5.0652e-06],\n",
      "          [-2.1546e-06, -2.0236e-05,  1.7629e-05,  ..., -1.8615e-06,\n",
      "           -4.3916e-06,  7.4221e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9180e-06, -2.3932e-08, -1.0834e-05,  ..., -3.4669e-05,\n",
      "           -2.2214e-05, -9.3140e-06],\n",
      "          [-1.1399e-05,  1.9413e-05,  8.4431e-06,  ..., -9.6937e-06,\n",
      "           -2.8399e-05,  6.7373e-06],\n",
      "          [-4.7524e-06,  3.5015e-06, -4.5695e-07,  ...,  2.3330e-05,\n",
      "           -1.7855e-05,  4.2265e-06],\n",
      "          ...,\n",
      "          [-1.6452e-05,  8.8947e-06,  2.4895e-06,  ...,  1.2460e-05,\n",
      "           -4.6137e-05, -1.0955e-05],\n",
      "          [ 4.9245e-06, -9.6276e-06, -4.4758e-06,  ...,  4.1607e-06,\n",
      "           -1.4803e-05, -1.7488e-05],\n",
      "          [ 2.0978e-06, -2.8200e-05,  3.2068e-06,  ..., -7.6067e-06,\n",
      "           -4.3157e-06, -1.8737e-06]],\n",
      "\n",
      "         [[-1.0094e-06,  9.6360e-06, -2.1723e-06,  ...,  2.2275e-05,\n",
      "            4.9102e-06, -2.7034e-06],\n",
      "          [-8.1886e-06, -1.7869e-05, -1.8769e-05,  ...,  3.5288e-06,\n",
      "           -2.3181e-05,  2.5753e-06],\n",
      "          [-7.2173e-06, -7.6166e-07, -1.7270e-07,  ...,  8.6506e-07,\n",
      "           -5.5389e-07, -9.5526e-06],\n",
      "          ...,\n",
      "          [-2.0351e-05,  2.4466e-06,  1.7373e-05,  ...,  1.3704e-05,\n",
      "           -9.9402e-06,  1.0872e-05],\n",
      "          [-4.6658e-06,  1.4891e-06,  2.9228e-05,  ...,  1.9981e-05,\n",
      "           -1.6296e-05,  4.0659e-06],\n",
      "          [ 2.9108e-06, -6.1140e-06, -5.3607e-06,  ...,  3.9752e-06,\n",
      "           -2.9585e-06,  4.3158e-06]],\n",
      "\n",
      "         [[-3.8959e-06, -1.0863e-05,  1.9612e-05,  ..., -1.0893e-05,\n",
      "            4.3819e-06,  2.8539e-06],\n",
      "          [ 7.1968e-06, -5.2315e-06,  1.5203e-05,  ...,  8.5129e-06,\n",
      "            1.3826e-05,  4.7334e-06],\n",
      "          [-9.6930e-07,  1.7670e-05, -1.1093e-05,  ...,  2.8891e-05,\n",
      "           -1.5901e-05, -1.9515e-05],\n",
      "          ...,\n",
      "          [ 3.9696e-06,  9.2477e-06,  1.1285e-05,  ...,  6.8828e-06,\n",
      "           -1.4675e-05, -1.6122e-05],\n",
      "          [ 1.7939e-05, -3.8344e-07, -2.1063e-05,  ...,  1.3463e-05,\n",
      "           -1.3179e-05,  1.2923e-05],\n",
      "          [-2.8679e-06, -6.1367e-06,  1.1287e-05,  ..., -5.2287e-06,\n",
      "           -1.4394e-05,  8.2116e-06]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[ 2.5559e-06, -7.4977e-07, -1.6626e-06,  ..., -4.0139e-07,\n",
      "           -4.2781e-06,  2.5892e-07],\n",
      "          [ 4.7528e-06,  3.2884e-06,  2.7536e-06,  ..., -3.2122e-06,\n",
      "            3.3175e-07,  6.3013e-07],\n",
      "          [ 3.5410e-06,  3.9779e-06,  4.3936e-06,  ...,  3.8823e-06,\n",
      "            2.6155e-06,  2.1708e-06],\n",
      "          ...,\n",
      "          [ 7.2721e-06,  1.1237e-05,  9.1987e-06,  ...,  4.2675e-06,\n",
      "            7.4220e-06,  1.5107e-06],\n",
      "          [ 2.4126e-06,  1.2463e-05,  8.8984e-06,  ...,  1.2447e-06,\n",
      "            2.4208e-06, -1.5179e-06],\n",
      "          [ 1.6816e-06,  6.8958e-06, -9.7497e-07,  ..., -6.1453e-07,\n",
      "           -6.2359e-07, -1.5756e-06]],\n",
      "\n",
      "         [[-2.7805e-06, -2.1742e-06,  2.7925e-07,  ..., -2.0626e-06,\n",
      "           -1.6614e-06, -1.1960e-06],\n",
      "          [-1.3050e-06, -1.7380e-06, -1.8132e-06,  ..., -7.2951e-07,\n",
      "           -8.1482e-07,  2.7710e-06],\n",
      "          [-1.8272e-06, -1.1324e-06, -3.1636e-06,  ...,  2.5143e-06,\n",
      "            4.1478e-06,  4.2579e-06],\n",
      "          ...,\n",
      "          [ 5.0326e-06,  1.6628e-06, -1.9074e-06,  ...,  3.5762e-06,\n",
      "            8.4807e-07,  1.4870e-06],\n",
      "          [ 2.3897e-06,  2.2346e-06,  2.6709e-06,  ...,  4.8344e-06,\n",
      "            1.3379e-06, -1.8544e-07],\n",
      "          [ 1.8786e-06,  4.2176e-06, -1.2032e-06,  ..., -1.1436e-06,\n",
      "           -2.1216e-06, -1.1108e-06]],\n",
      "\n",
      "         [[ 1.8082e-06, -2.6924e-07, -3.2143e-07,  ..., -3.1614e-06,\n",
      "            1.4587e-06, -1.4692e-06],\n",
      "          [ 2.7480e-06,  3.9441e-06,  1.2609e-06,  ...,  1.0127e-06,\n",
      "            1.3433e-06, -2.7661e-06],\n",
      "          [-3.3559e-06, -2.7388e-06, -2.2845e-06,  ..., -4.4491e-06,\n",
      "           -4.8455e-07, -2.4096e-06],\n",
      "          ...,\n",
      "          [-4.9515e-06, -6.6690e-07, -5.5740e-07,  ..., -1.6064e-06,\n",
      "            4.1164e-06, -9.2105e-07],\n",
      "          [-3.5090e-07, -1.7209e-06, -6.7625e-07,  ..., -7.9464e-06,\n",
      "            2.9829e-08, -5.9746e-06],\n",
      "          [-2.6927e-06, -1.5953e-06, -1.0629e-06,  ..., -2.2482e-06,\n",
      "           -3.6194e-06, -2.3256e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0590e-07,  6.5151e-06,  3.9021e-06,  ...,  6.1415e-06,\n",
      "            3.7706e-07, -3.3619e-06],\n",
      "          [ 1.1697e-06,  1.3542e-05,  8.3998e-06,  ...,  9.5763e-06,\n",
      "            4.2381e-06, -4.2587e-06],\n",
      "          [ 1.0142e-06,  2.0522e-05,  2.2583e-05,  ...,  1.6292e-05,\n",
      "            6.4818e-06, -1.0019e-07],\n",
      "          ...,\n",
      "          [-4.3445e-07,  1.5991e-05,  2.4941e-05,  ...,  1.6205e-05,\n",
      "            1.0240e-05, -2.5957e-07],\n",
      "          [ 1.6172e-06,  1.7312e-05,  1.8413e-05,  ...,  2.0569e-05,\n",
      "            1.5468e-05,  3.9974e-06],\n",
      "          [-1.1738e-06,  9.6336e-06,  4.7510e-06,  ...,  1.2576e-05,\n",
      "            1.2089e-05,  4.1135e-06]],\n",
      "\n",
      "         [[-7.8548e-07, -1.8869e-06, -3.0930e-06,  ..., -6.6917e-06,\n",
      "           -2.1945e-06, -8.6666e-07],\n",
      "          [-6.8394e-07, -2.4388e-06, -3.2556e-06,  ..., -4.1281e-06,\n",
      "           -4.5428e-06,  2.6669e-07],\n",
      "          [-7.5222e-07, -5.7756e-06, -1.1911e-05,  ..., -1.1028e-05,\n",
      "           -5.6471e-06,  1.8511e-07],\n",
      "          ...,\n",
      "          [-4.6308e-06, -2.8021e-06, -1.0915e-05,  ..., -8.0840e-06,\n",
      "            7.6521e-07,  9.0416e-07],\n",
      "          [-5.9212e-06, -2.6510e-06, -1.3758e-05,  ..., -2.8209e-06,\n",
      "            2.2814e-06,  1.5621e-06],\n",
      "          [-4.9455e-06, -2.7174e-06, -2.2949e-06,  ..., -2.1712e-06,\n",
      "            3.1977e-07,  2.3321e-06]],\n",
      "\n",
      "         [[ 8.4756e-07,  1.7700e-07, -2.1322e-06,  ...,  1.3956e-07,\n",
      "            1.6544e-07,  3.1014e-06],\n",
      "          [ 4.0322e-06,  3.2168e-07,  4.7923e-06,  ...,  1.5077e-06,\n",
      "            4.4325e-06,  6.9037e-06],\n",
      "          [-1.1545e-07, -3.2342e-06, -1.1506e-06,  ..., -3.8237e-06,\n",
      "            4.7823e-07,  4.7240e-06],\n",
      "          ...,\n",
      "          [-3.0054e-06,  2.0458e-06,  1.1018e-06,  ...,  7.9301e-07,\n",
      "            3.5525e-06,  6.5551e-06],\n",
      "          [-1.2769e-06, -7.9321e-07, -2.9575e-06,  ..., -3.7073e-06,\n",
      "            1.1263e-06,  6.1718e-06],\n",
      "          [-3.3606e-06, -1.6083e-06, -7.1319e-07,  ..., -9.2104e-07,\n",
      "           -1.8303e-06,  1.9173e-06]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[-1.2026e-06, -7.5305e-07, -8.1441e-07,  ..., -9.5961e-07,\n",
      "           -7.2399e-07, -4.0472e-07],\n",
      "          [-1.4878e-06, -1.6138e-07, -1.1784e-06,  ..., -1.0854e-06,\n",
      "           -1.8015e-06, -6.6905e-07],\n",
      "          [-1.8564e-06, -2.8256e-07, -8.8200e-07,  ..., -6.7694e-07,\n",
      "           -1.2024e-06, -7.8769e-07],\n",
      "          ...,\n",
      "          [-2.0620e-06,  6.6774e-08, -1.0987e-06,  ..., -4.1812e-07,\n",
      "            6.4493e-07,  4.2074e-07],\n",
      "          [-7.6211e-07,  1.7842e-07,  5.2097e-07,  ...,  5.1221e-07,\n",
      "            6.2269e-07,  5.3999e-07],\n",
      "          [-8.3858e-07, -3.7327e-07, -1.6777e-07,  ...,  2.7177e-07,\n",
      "            8.0111e-07,  6.6719e-07]],\n",
      "\n",
      "         [[-1.1895e-06, -9.9354e-07, -6.4825e-07,  ..., -3.5299e-07,\n",
      "           -4.7710e-07, -1.0945e-07],\n",
      "          [-5.5021e-07, -3.0356e-07, -5.5299e-07,  ...,  7.0950e-08,\n",
      "            9.9596e-08, -2.7816e-09],\n",
      "          [-9.5798e-07, -7.4331e-07, -1.1536e-06,  ..., -7.5306e-07,\n",
      "           -4.4507e-07, -1.2482e-07],\n",
      "          ...,\n",
      "          [ 2.5575e-07, -1.1824e-07, -8.4931e-07,  ..., -7.9505e-07,\n",
      "           -6.4769e-07, -1.1548e-07],\n",
      "          [ 1.6694e-06,  9.5826e-07,  1.1206e-06,  ...,  2.9426e-07,\n",
      "            1.5116e-07,  1.0240e-07],\n",
      "          [ 3.6224e-07,  2.2325e-07,  3.3183e-07,  ...,  2.6073e-07,\n",
      "            3.7326e-07,  7.3495e-08]],\n",
      "\n",
      "         [[ 1.1735e-06,  9.2000e-07,  1.0936e-06,  ..., -7.6091e-07,\n",
      "           -5.0573e-07, -4.3073e-07],\n",
      "          [-5.5880e-07, -1.6814e-06, -1.9425e-07,  ..., -1.8090e-06,\n",
      "           -1.3828e-06, -3.8642e-07],\n",
      "          [ 7.1706e-07, -1.2567e-07,  1.4215e-06,  ...,  2.6489e-07,\n",
      "            3.0564e-07, -1.5646e-07],\n",
      "          ...,\n",
      "          [-5.8173e-08,  9.2166e-08,  1.5486e-06,  ...,  6.7556e-07,\n",
      "            2.4073e-06,  9.7053e-07],\n",
      "          [-9.0264e-07, -1.0377e-06, -7.1062e-07,  ...,  3.0427e-07,\n",
      "            9.1868e-07,  9.6457e-07],\n",
      "          [-1.2908e-06, -1.6124e-06, -9.9062e-07,  ...,  7.7015e-07,\n",
      "            7.8756e-07,  8.0798e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6848e-07, -4.2102e-08, -8.2968e-07,  ..., -3.1996e-07,\n",
      "           -3.1441e-07, -1.5256e-07],\n",
      "          [ 2.2071e-07,  1.8898e-06,  1.8999e-06,  ...,  1.6818e-06,\n",
      "            1.3310e-06,  1.6270e-07],\n",
      "          [-6.5229e-07,  1.8537e-06,  1.9758e-06,  ...,  9.9050e-07,\n",
      "            1.4836e-06,  4.6907e-07],\n",
      "          ...,\n",
      "          [-5.0357e-07,  2.5091e-06,  1.6981e-06,  ...,  8.0776e-07,\n",
      "           -8.6999e-07, -1.3876e-06],\n",
      "          [-3.0814e-07,  2.0303e-06,  2.2786e-06,  ...,  7.0533e-07,\n",
      "            6.5750e-07, -9.2332e-07],\n",
      "          [-2.9290e-07,  3.9736e-07, -3.2714e-07,  ..., -4.2198e-07,\n",
      "           -5.2212e-07, -5.9683e-07]],\n",
      "\n",
      "         [[ 6.5117e-07,  6.0541e-07,  1.0332e-06,  ...,  2.9178e-07,\n",
      "           -3.0091e-07,  1.0409e-07],\n",
      "          [ 8.9714e-07,  1.7364e-07,  4.6824e-07,  ..., -6.9288e-07,\n",
      "           -7.2251e-07, -7.3663e-07],\n",
      "          [ 1.5529e-06,  6.6950e-07,  4.0554e-07,  ..., -5.0464e-07,\n",
      "           -1.8429e-07, -1.5466e-07],\n",
      "          ...,\n",
      "          [ 1.3500e-06, -3.4658e-07, -7.8122e-07,  ..., -1.3691e-06,\n",
      "           -1.3190e-06, -1.3325e-06],\n",
      "          [ 4.2802e-07, -4.9582e-07, -5.1066e-07,  ..., -4.5543e-07,\n",
      "           -1.8396e-07, -1.0461e-06],\n",
      "          [ 4.9799e-07, -3.5880e-07,  2.4192e-07,  ...,  1.3010e-07,\n",
      "            5.0276e-08, -1.5598e-07]],\n",
      "\n",
      "         [[ 7.1930e-07,  1.2269e-06,  8.6176e-07,  ..., -1.4400e-07,\n",
      "           -1.6739e-07,  2.2523e-07],\n",
      "          [-3.1819e-07, -1.8138e-07, -2.3781e-07,  ..., -1.1889e-06,\n",
      "           -9.1441e-07, -5.6349e-08],\n",
      "          [-2.5875e-07,  4.6319e-07,  8.7206e-07,  ..., -9.8232e-07,\n",
      "           -2.3198e-08, -2.2974e-07],\n",
      "          ...,\n",
      "          [-5.8533e-07, -5.8204e-07,  5.7695e-07,  ...,  1.3422e-07,\n",
      "            4.9930e-07, -1.5112e-07],\n",
      "          [-4.5828e-07, -4.7689e-08,  3.0815e-07,  ...,  3.0852e-07,\n",
      "            3.4067e-07, -7.6198e-07],\n",
      "          [-4.1223e-07,  1.1837e-07,  8.5719e-07,  ...,  4.6160e-07,\n",
      "            9.4484e-07, -3.4125e-07]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[-7.1179e-08, -1.2761e-08, -1.4351e-07,  ..., -1.7831e-08,\n",
      "           -1.6043e-07, -1.5791e-07],\n",
      "          [ 1.5329e-07,  2.4050e-07,  2.7554e-07,  ...,  1.4161e-07,\n",
      "            4.5995e-08, -1.6625e-08],\n",
      "          [ 1.9679e-07,  2.9402e-07,  2.7235e-07,  ...,  5.8000e-08,\n",
      "           -9.9757e-08, -6.3132e-08],\n",
      "          ...,\n",
      "          [ 3.3398e-08,  4.1755e-08, -6.9133e-08,  ..., -1.0887e-07,\n",
      "           -5.2839e-08,  3.6778e-08],\n",
      "          [ 1.5333e-07,  3.8586e-07,  1.6931e-07,  ...,  1.5122e-07,\n",
      "            7.1145e-08,  2.3801e-07],\n",
      "          [-4.9702e-08,  2.1269e-08,  1.4936e-08,  ...,  1.5622e-07,\n",
      "            7.5645e-08,  2.3151e-07]],\n",
      "\n",
      "         [[ 1.0061e-07,  2.3432e-07,  1.6400e-07,  ...,  2.5969e-07,\n",
      "           -9.4195e-09, -2.1019e-08],\n",
      "          [ 2.3152e-07,  4.4081e-07,  4.2322e-07,  ...,  3.6334e-07,\n",
      "           -7.1866e-08, -1.7722e-07],\n",
      "          [ 3.2866e-07,  4.0682e-07,  4.1498e-07,  ...,  4.3859e-07,\n",
      "           -3.6790e-08, -5.1080e-08],\n",
      "          ...,\n",
      "          [ 1.1439e-07,  2.4391e-07,  2.3853e-07,  ...,  1.5553e-07,\n",
      "           -6.1492e-09,  7.9376e-08],\n",
      "          [ 1.2671e-07,  2.8517e-07,  1.7275e-07,  ...,  1.7850e-07,\n",
      "            4.0670e-08,  1.0520e-07],\n",
      "          [-2.4302e-08,  1.3339e-07, -1.5628e-08,  ...,  7.6133e-08,\n",
      "            2.7181e-08,  3.0408e-08]],\n",
      "\n",
      "         [[ 9.7765e-09,  1.6948e-07,  1.1863e-07,  ...,  1.9889e-07,\n",
      "            2.8883e-07,  2.9545e-07],\n",
      "          [ 6.2659e-08,  1.0938e-07,  1.0447e-07,  ...,  2.6149e-07,\n",
      "            3.2389e-07,  3.8145e-07],\n",
      "          [-9.2100e-09,  5.2290e-08,  6.1457e-08,  ...,  2.8932e-08,\n",
      "            1.5792e-07,  3.3822e-07],\n",
      "          ...,\n",
      "          [ 1.1384e-07,  1.1420e-07,  1.9939e-07,  ...,  9.9334e-08,\n",
      "            2.3517e-07,  2.4882e-07],\n",
      "          [-4.6995e-08, -1.3618e-07,  9.4670e-08,  ..., -1.2628e-07,\n",
      "            2.1640e-08,  6.4009e-08],\n",
      "          [-1.0109e-09, -3.6286e-08,  7.5056e-08,  ...,  5.4872e-08,\n",
      "            3.1099e-08,  8.4825e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.2414e-08, -2.4049e-07, -1.9655e-07,  ..., -4.1539e-07,\n",
      "           -3.4101e-07, -1.2943e-07],\n",
      "          [-1.1246e-07, -6.3986e-07, -5.1112e-07,  ..., -5.8485e-07,\n",
      "           -4.2331e-07, -1.5590e-07],\n",
      "          [-1.7443e-07, -7.0934e-07, -4.1621e-07,  ..., -3.8793e-07,\n",
      "           -2.8521e-07,  1.7174e-08],\n",
      "          ...,\n",
      "          [-3.7187e-08, -7.0400e-07, -3.7864e-07,  ..., -5.6979e-07,\n",
      "           -5.3803e-07, -9.0652e-08],\n",
      "          [-1.2666e-09, -4.0848e-07, -3.3050e-07,  ..., -4.3674e-07,\n",
      "           -5.3893e-07, -1.7600e-07],\n",
      "          [-3.0505e-08, -2.3804e-07, -2.1202e-07,  ..., -2.8416e-07,\n",
      "           -3.2255e-07, -1.2545e-07]],\n",
      "\n",
      "         [[-1.5938e-07, -2.3974e-07, -1.1678e-07,  ..., -2.6090e-08,\n",
      "            6.4435e-08,  9.4883e-08],\n",
      "          [-1.1749e-07, -2.6538e-07,  1.3989e-08,  ...,  4.9702e-08,\n",
      "            1.9808e-08,  2.7218e-08],\n",
      "          [-2.0534e-07, -3.7508e-07,  4.7120e-08,  ...,  1.2288e-07,\n",
      "            2.7543e-07,  2.0525e-07],\n",
      "          ...,\n",
      "          [-1.0442e-07, -3.9047e-07,  5.6017e-08,  ...,  2.6130e-07,\n",
      "            3.6947e-07,  2.1508e-07],\n",
      "          [-1.2760e-07, -3.3039e-07,  1.1210e-07,  ...,  2.3484e-07,\n",
      "            2.3382e-07,  2.2597e-08],\n",
      "          [-5.0959e-08, -1.9404e-07,  4.2702e-08,  ...,  1.2454e-07,\n",
      "            1.3533e-07, -4.3679e-08]],\n",
      "\n",
      "         [[-1.1473e-08,  2.7128e-08, -9.7969e-08,  ..., -6.4731e-08,\n",
      "            8.4638e-08, -2.6493e-08],\n",
      "          [-4.4236e-08, -4.7080e-08, -4.9434e-10,  ...,  4.9712e-08,\n",
      "            2.1041e-07,  1.5011e-07],\n",
      "          [ 8.4131e-08,  2.4820e-08,  1.5628e-07,  ...,  5.5886e-08,\n",
      "            2.2506e-07,  1.3037e-07],\n",
      "          ...,\n",
      "          [ 5.4784e-08, -1.3195e-07, -9.9080e-08,  ...,  4.5577e-08,\n",
      "            3.2697e-08,  3.6805e-08],\n",
      "          [-3.2791e-08, -1.1289e-07, -5.5656e-08,  ...,  1.4162e-07,\n",
      "            7.6474e-08,  8.4204e-08],\n",
      "          [ 5.2116e-08, -9.9016e-08, -4.4872e-08,  ...,  1.4432e-07,\n",
      "            1.1676e-07,  8.5024e-08]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[-1.8042e-07, -1.5124e-07,  2.1559e-07,  2.6787e-08],\n",
      "          [-2.6467e-07, -1.9983e-07,  8.2576e-08,  6.1911e-08],\n",
      "          [-3.7253e-07, -1.0056e-07,  3.1091e-07,  1.7988e-07],\n",
      "          [-3.2073e-08,  9.9373e-08,  9.9215e-08,  1.0356e-09]],\n",
      "\n",
      "         [[-5.6280e-08, -1.5648e-08, -1.1538e-07, -7.1386e-08],\n",
      "          [ 1.1766e-07,  7.2059e-08, -2.3567e-07, -5.5395e-08],\n",
      "          [ 5.1612e-08,  1.5907e-07,  8.8214e-08,  9.0908e-08],\n",
      "          [ 1.2197e-07,  2.4086e-07,  3.9781e-08, -6.9276e-08]],\n",
      "\n",
      "         [[ 6.8480e-08,  1.1232e-08,  7.1734e-08, -1.0099e-07],\n",
      "          [-9.3152e-08,  9.0781e-08,  2.6920e-07,  7.9926e-08],\n",
      "          [-4.2537e-08, -3.0414e-08, -2.2320e-08,  6.1166e-08],\n",
      "          [-1.0598e-07, -1.9614e-07, -2.9193e-08,  1.9754e-07]],\n",
      "\n",
      "         [[-6.9596e-08,  3.3024e-08, -7.0313e-08,  6.4678e-08],\n",
      "          [ 8.4657e-08,  5.3781e-08, -2.8500e-07, -5.8260e-08],\n",
      "          [-4.1699e-08,  1.5540e-07, -2.6433e-07,  2.4375e-08],\n",
      "          [-8.0752e-08,  9.5906e-08, -4.2881e-08,  5.6749e-08]],\n",
      "\n",
      "         [[ 2.5445e-07,  6.9993e-08, -1.3336e-07,  7.1725e-08],\n",
      "          [-5.7176e-08, -1.3071e-07, -1.9560e-07, -4.2893e-08],\n",
      "          [ 1.1771e-07,  1.9014e-07, -1.2376e-07, -5.0710e-08],\n",
      "          [-2.2964e-07,  4.1545e-08, -6.3221e-08,  6.5494e-08]],\n",
      "\n",
      "         [[ 2.8341e-09,  1.8725e-07,  1.1030e-07, -4.2954e-08],\n",
      "          [ 8.9782e-08,  1.7152e-07, -2.9910e-08, -9.1675e-08],\n",
      "          [-6.9233e-08,  7.7397e-08,  1.4497e-07,  5.2786e-08],\n",
      "          [-1.5868e-07,  2.2057e-08,  1.2342e-07,  1.3420e-07]],\n",
      "\n",
      "         [[ 3.5611e-08, -1.7004e-07, -1.1139e-07,  1.1151e-08],\n",
      "          [-6.3433e-08, -2.6723e-07,  2.6674e-07,  2.6481e-07],\n",
      "          [-4.8803e-08, -2.6297e-07,  3.5466e-07, -2.6546e-08],\n",
      "          [ 2.6075e-07,  1.9529e-07,  1.9900e-07, -2.5410e-07]],\n",
      "\n",
      "         [[-8.8705e-08,  1.6253e-07, -4.2262e-08, -2.1999e-08],\n",
      "          [-1.4358e-07, -3.2578e-08,  8.2195e-08,  1.6901e-08],\n",
      "          [-7.4801e-08,  6.3745e-08, -1.6666e-08,  4.7582e-08],\n",
      "          [ 1.0628e-07,  5.5807e-08, -7.7684e-08, -9.0563e-08]],\n",
      "\n",
      "         [[-2.8081e-08, -8.3076e-08, -3.1860e-08, -1.3187e-07],\n",
      "          [ 1.2872e-07,  1.0957e-07,  1.9180e-08,  2.5150e-07],\n",
      "          [-9.0497e-09, -7.2019e-08, -2.9294e-09,  2.7915e-07],\n",
      "          [ 7.8190e-08, -5.2245e-08,  2.8926e-08,  1.2975e-07]],\n",
      "\n",
      "         [[ 8.3893e-08, -2.0653e-07,  1.6552e-07, -5.3423e-08],\n",
      "          [-1.6443e-07, -1.5915e-07,  3.7724e-07,  1.1069e-07],\n",
      "          [ 2.2437e-07,  1.8694e-08,  1.2157e-07,  8.3375e-08],\n",
      "          [ 1.3867e-07, -1.5862e-07, -3.9030e-08, -1.8456e-08]],\n",
      "\n",
      "         [[ 8.3543e-08,  2.1000e-07, -9.6211e-08,  6.6767e-08],\n",
      "          [-1.5939e-09,  2.1110e-07, -2.7142e-07,  4.8378e-08],\n",
      "          [ 1.5762e-07,  3.3061e-07,  1.6983e-08,  4.8506e-08],\n",
      "          [-6.1603e-08,  3.2121e-08, -2.7252e-08, -8.4373e-08]],\n",
      "\n",
      "         [[ 1.5826e-07, -3.8146e-08, -2.4253e-08, -8.0040e-09],\n",
      "          [ 1.7757e-07,  3.4018e-08,  1.9701e-07,  2.9163e-07],\n",
      "          [ 2.3013e-07, -1.0069e-07, -1.4590e-08,  2.3637e-08],\n",
      "          [ 1.3910e-07, -2.4320e-08,  1.7519e-07,  7.6207e-08]],\n",
      "\n",
      "         [[ 1.2453e-07,  4.1849e-08,  4.3957e-08,  8.4168e-08],\n",
      "          [-1.4894e-07, -2.1726e-07,  1.4400e-07, -8.2972e-08],\n",
      "          [ 1.7348e-07,  9.8270e-08, -4.1685e-08, -2.9115e-07],\n",
      "          [-2.5822e-09,  1.4210e-07,  5.0082e-08, -1.1122e-07]],\n",
      "\n",
      "         [[ 8.9538e-08,  8.0629e-08, -4.3054e-08,  1.3082e-07],\n",
      "          [-6.4946e-08,  3.4227e-08, -1.2485e-07, -8.8347e-08],\n",
      "          [-1.3889e-07, -9.0685e-08, -1.2403e-07,  1.2911e-07],\n",
      "          [ 1.2263e-07,  1.4615e-10,  3.6484e-09,  1.4950e-07]],\n",
      "\n",
      "         [[-1.4975e-07,  1.3034e-07,  6.9103e-08, -2.3020e-08],\n",
      "          [-6.6938e-08,  2.6187e-08,  1.6372e-07,  3.2738e-08],\n",
      "          [ 2.8925e-07, -4.9650e-08, -3.0104e-08, -5.8593e-08],\n",
      "          [ 1.1612e-07,  5.4175e-08, -1.5299e-07, -5.8711e-08]],\n",
      "\n",
      "         [[ 8.1073e-08, -1.0125e-07, -1.2945e-09, -3.8884e-08],\n",
      "          [ 2.3225e-07, -4.0462e-08,  2.0190e-09, -5.1430e-08],\n",
      "          [ 2.2469e-07, -1.1819e-07,  8.2808e-08,  5.5518e-08],\n",
      "          [-4.6948e-08, -1.9858e-07,  7.8302e-08,  1.0860e-07]],\n",
      "\n",
      "         [[ 4.6383e-08, -1.8677e-07,  2.3132e-07,  4.7620e-08],\n",
      "          [ 6.6458e-08, -7.2403e-08,  2.7186e-07,  1.1936e-07],\n",
      "          [-5.3488e-08, -2.7610e-07,  2.1276e-07, -8.3580e-08],\n",
      "          [ 9.7424e-08, -5.0170e-08,  6.2312e-08, -7.2127e-08]],\n",
      "\n",
      "         [[ 9.9498e-08,  2.2954e-07,  1.0209e-08,  1.1151e-08],\n",
      "          [-2.0386e-07, -3.3957e-08,  8.1719e-08,  1.3909e-07],\n",
      "          [-1.6130e-07, -7.9329e-08,  1.0967e-07,  1.5565e-07],\n",
      "          [-9.0251e-08, -4.7992e-08,  2.3806e-07,  6.7164e-08]],\n",
      "\n",
      "         [[ 1.9688e-07,  2.9349e-07, -1.4762e-07,  1.4817e-08],\n",
      "          [-3.5125e-09,  2.6540e-07, -6.4002e-08,  1.3924e-07],\n",
      "          [-2.5019e-07,  2.0003e-08,  2.3328e-08,  1.3652e-07],\n",
      "          [ 1.6023e-08,  1.7680e-07, -1.1501e-08,  8.3003e-08]],\n",
      "\n",
      "         [[ 3.3506e-08, -5.5824e-08,  7.7906e-08, -4.6544e-08],\n",
      "          [-9.5208e-09, -7.7100e-08,  1.3654e-07, -1.3101e-07],\n",
      "          [-2.7886e-07, -2.7229e-07, -1.3486e-08, -4.1953e-09],\n",
      "          [-2.7200e-07, -4.4560e-07,  3.9702e-08,  2.0608e-07]],\n",
      "\n",
      "         [[-3.7653e-08, -8.7284e-09,  3.1727e-08,  7.6577e-08],\n",
      "          [-1.3843e-07,  4.2787e-08, -9.0185e-08,  1.1919e-07],\n",
      "          [ 1.8749e-09,  8.9119e-08, -1.0105e-07, -1.0863e-08],\n",
      "          [ 3.8956e-08,  1.7224e-07,  1.1168e-07, -3.6780e-08]],\n",
      "\n",
      "         [[-4.6745e-08, -1.0444e-07,  6.9772e-08, -5.6054e-08],\n",
      "          [-1.5730e-08, -3.0667e-07,  8.0742e-08, -1.9005e-07],\n",
      "          [-3.9272e-09,  1.2134e-09,  1.2406e-07, -2.2286e-07],\n",
      "          [-7.5248e-08,  7.5771e-08,  1.0021e-07, -1.4753e-07]],\n",
      "\n",
      "         [[-1.7427e-07, -7.0954e-08, -4.2259e-08,  1.2492e-07],\n",
      "          [-1.0750e-07,  8.9938e-08, -1.8351e-07,  1.4807e-07],\n",
      "          [-5.0940e-08,  4.7531e-10, -1.5737e-07,  2.0853e-07],\n",
      "          [-6.5600e-08, -6.4648e-08, -1.2228e-07,  2.0153e-07]],\n",
      "\n",
      "         [[ 6.4706e-08,  8.5583e-08,  8.6911e-08,  2.4841e-07],\n",
      "          [ 1.4320e-07,  1.3081e-07,  1.2684e-08,  2.7132e-08],\n",
      "          [-2.9283e-07, -1.9271e-07, -2.2089e-07,  5.4667e-08],\n",
      "          [-2.9093e-08,  4.5615e-08, -1.1510e-07, -9.4822e-09]],\n",
      "\n",
      "         [[-8.5069e-08, -1.8755e-07,  3.8034e-08, -2.0708e-09],\n",
      "          [-1.0752e-07, -6.9349e-08,  2.8951e-07,  2.3203e-08],\n",
      "          [-1.2363e-07, -1.1453e-07,  2.0669e-07, -8.7859e-08],\n",
      "          [ 1.1801e-08, -1.8577e-08,  1.4663e-07, -1.4288e-07]],\n",
      "\n",
      "         [[-6.7284e-08, -2.7470e-07, -7.1013e-08,  1.6073e-07],\n",
      "          [ 4.6988e-08, -3.4362e-07, -3.1134e-07,  9.0861e-08],\n",
      "          [-1.1781e-07, -1.6684e-07, -1.4407e-07, -2.4305e-08],\n",
      "          [ 1.0806e-07,  1.2232e-07, -1.1779e-07, -2.3004e-07]],\n",
      "\n",
      "         [[-5.8181e-08, -1.6283e-07,  5.7446e-08, -1.1975e-08],\n",
      "          [-5.0004e-08,  8.9619e-08,  2.6192e-07,  2.6076e-07],\n",
      "          [ 9.7417e-08,  8.1367e-08,  2.8758e-07,  2.2677e-07],\n",
      "          [ 1.9556e-07,  8.7837e-08,  1.4648e-07,  3.3426e-08]],\n",
      "\n",
      "         [[-1.0690e-07, -1.0034e-07,  1.4318e-08, -3.4806e-08],\n",
      "          [-6.6302e-08, -4.2476e-08, -1.2545e-07,  4.2266e-08],\n",
      "          [-1.6840e-07, -6.7648e-08, -9.2350e-08,  6.8942e-08],\n",
      "          [-3.4749e-07, -1.2132e-07, -3.0449e-09,  1.6832e-07]],\n",
      "\n",
      "         [[-4.8981e-08,  1.3734e-07,  1.6787e-07,  9.0078e-08],\n",
      "          [ 1.8414e-07,  3.0247e-07,  1.9649e-07,  2.0150e-07],\n",
      "          [-1.3652e-07,  5.8500e-08,  5.7466e-08, -5.2136e-08],\n",
      "          [-1.6092e-07,  6.8533e-08,  9.1395e-08, -7.3134e-08]],\n",
      "\n",
      "         [[-2.3040e-07,  1.4908e-07, -1.6510e-07, -5.1056e-08],\n",
      "          [-1.8535e-07,  1.6309e-07, -1.1355e-07, -8.0499e-08],\n",
      "          [-1.3911e-07,  9.6109e-08,  8.1155e-08, -5.7553e-08],\n",
      "          [-6.0449e-08, -7.8210e-08, -4.7862e-09, -1.0887e-07]],\n",
      "\n",
      "         [[ 4.7727e-08, -5.8798e-08,  1.0791e-07, -1.2168e-07],\n",
      "          [ 1.6679e-08, -1.9409e-07,  5.9959e-08, -1.1405e-07],\n",
      "          [ 5.6759e-08, -7.5712e-08,  1.4364e-07, -1.1509e-07],\n",
      "          [-7.9311e-08, -1.8006e-08,  2.1293e-07,  6.4116e-08]],\n",
      "\n",
      "         [[ 1.1152e-07, -1.5940e-07,  3.6727e-08,  7.9740e-08],\n",
      "          [ 2.2283e-07, -7.8837e-08,  1.9672e-07,  9.2010e-08],\n",
      "          [-3.2586e-08, -3.0893e-07, -8.4008e-09, -7.7352e-08],\n",
      "          [-6.9567e-08, -7.1363e-08,  2.3004e-08,  2.2766e-08]],\n",
      "\n",
      "         [[-3.5773e-08,  6.1728e-09, -1.9487e-07, -1.6631e-07],\n",
      "          [ 7.4488e-09, -1.2623e-07, -1.8837e-07, -6.5358e-08],\n",
      "          [-7.3309e-08, -2.9088e-08,  6.0893e-08,  5.5883e-08],\n",
      "          [-7.1934e-08,  2.5368e-08,  1.8976e-07, -8.0206e-08]],\n",
      "\n",
      "         [[-3.3024e-08,  8.4881e-08,  1.1331e-07,  4.7684e-08],\n",
      "          [-1.2933e-08,  3.4572e-08,  2.9590e-07, -5.4158e-09],\n",
      "          [-8.4022e-08, -4.1051e-07, -8.7103e-08, -1.1673e-08],\n",
      "          [ 9.9761e-08, -2.0505e-07, -1.1009e-07, -1.0103e-08]],\n",
      "\n",
      "         [[ 8.8637e-08, -1.6398e-07, -2.6049e-07,  4.0882e-09],\n",
      "          [ 1.3108e-08, -2.1718e-08, -1.2949e-07, -1.5301e-07],\n",
      "          [ 2.7686e-08,  1.2001e-07, -3.2877e-08, -1.7770e-07],\n",
      "          [-1.1880e-08,  9.0717e-08, -1.7338e-08,  1.0013e-08]],\n",
      "\n",
      "         [[ 1.7274e-08, -1.9067e-08, -7.8976e-08,  3.4357e-08],\n",
      "          [-3.0493e-07, -1.3150e-07,  9.6520e-08,  2.1091e-07],\n",
      "          [-8.6734e-08, -7.3666e-08,  1.0012e-07,  1.4039e-07],\n",
      "          [-2.5812e-08, -8.4582e-08,  1.4088e-07,  1.6176e-08]]]],\n",
      "       device='cuda:0', grad_fn=<ConvolutionBackward0>)])\n"
     ]
    }
   ],
   "source": [
    "effdet_model.eval()\n",
    "dummy_input = torch.randn(1, 3, 512, 512).to(device)  # Batch of 1, 3 channels, 512x512 image\n",
    "outputs = effdet_model(dummy_input)\n",
    "\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
